---
title: "Short S & P Analysis"
author: "Michael Dowd"
date: "12/4/2019"
output: html_document
---

```{r setup, include=FALSE, results='hide'}
knitr::opts_chunk$set(echo = FALSE)
library('tidyverse')
library('lubridate')
library('reshape2')
library('corrplot')
library('RcppRoll')
library('ggjoy')
library('gridExtra')
library('caret')
library('mlbench')
library('nnet')
library('rlist')
library('xgboost')
set.seed(42)
```

```{r Global Variables, include=FALSE, results='hide'}
# Analysis Mode
# 0 - Full Backtest: run over a over historic days with retraining after every day
# 1 - Retrain: retrain models using the latest data
# 2 - Prediction: just load data and run predictions using the latest data
# 3 - Partial Backtest: for debugging, skip the retraining 
ANALYSIS_MODE = 1
BACKTEST_DAYS = 500
MODEL_TRAINING_DAYS = 500
ENSEMBLE_TRAINING_DAYS = 500

# Targets and Features
DATA_FILES <- c('SANDP.csv', 'DJI.csv', 'VIX.csv')
TARGET_COLS <- c('SANDP.Close')
TARGET_LEADS <- c(0) 
TARGET_DIFFS <- c(-0.1, -0.7) # std diff
FEATURE_COLS <- c('SANDP.Open', 'SANDP.High', 'SANDP.Low', 'SANDP.Close', 'DJI.Close', 'VIX.Close')
FEATURE_LAGS <- c(0, 1, 1, 1, 1, 1) 

# Feature Engineering
SHORT_MAS <- c(5, 7, 10, 15)
LONG_MAS <- c(12, 20, 30, 40)
AGGREGATE_WINDOWS <- c(5) #, 10, 20) # 3
AGGREGATE_FUNCTIONS <- c('Mean') #, 'SD') # 3 x 2 = 6
LAGSTEPS <- 5 # 6 x (5 + 1) = 36, variable multiplier
DIFF_CLASSES <- c(0.1) # , 1, 2) # labels for small move, medium move and large move

# Display Options
VARS_TO_SHOW <-  20
```

```{r Functions, include=FALSE, results='hide'}

# --------------------------------------------------------
# Top Level Functions---------------------------------------

master_dataframe <- function(Files, Columns) {
  parent_path <- substr(getwd(), 1, regexpr("\\/[^\\/]*$", getwd()))
  path <- paste(parent_path, 'Data/', sep = "")
  dataframes = vector("list", length(Files))
  for (i in 1 : length(Files)) {
    file <- Files[i]
    prefix <- str_replace(file, 'csv', '')
    df <- read_csv(paste(path, file, sep = ""))
    df <- df %>%
      mutate(Date=as.numeric(format(strptime(Date,"%Y-%m-%d"),"%Y%m%d"))) %>%
      discard(~all(is.na(.x))) %>%
      select(which(colSums(.) != 0)) %>%
      mutate(Date= as.Date(as.character(Date), "%Y%m%d")) %>%
      select(one_of(c('Date', str_replace(Columns, prefix, ''))))
    
    names(df)[-1] <- paste(prefix, colnames(df)[-1], sep = "")

    if (i == 1) {
      master <- df
    }
    else {
      master <- merge(master, df, by="Date")
    }
  }  
  return(master)
}

create_dateranges <- function(Features, Labels) {
  dates = Features %>%
    merge(Labels, by = "Date", all = FALSE) %>%
    select(Date)
  dataframes = list()
  steps = c(1)
  n = length(dates$Date)
  if (ANALYSIS_MODE == 0 | ANALYSIS_MODE == 3) steps <- c(BACKTEST_DAYS:1)
  index = 1
  for (i in steps) {
    latest_date = sort(dates$Date,partial=n-i)[n-i]
    filtered = dates %>%
      filter(Date <= latest_date) %>%
      arrange(desc(Date)) %>%
      top_n(MODEL_TRAINING_DAYS + ENSEMBLE_TRAINING_DAYS)
    dataframes[i] = list(filtered)
    index = index + 1
  }
  
  return(dataframes)
}

extract_training_data <- function(Dates, Features, Labels, Mode = 'MODEL') {
  labels <-  Labels %>%
    merge(Dates, by = "Date", all = FALSE) %>%
    mutate_at(vars(-Date), ~ . - lag(., 1)) %>%
    drop_na()
  
  names(labels)[-1] <- paste(colnames(labels)[-1], 'DIFF1', sep = ".")
  
  extract_amount <- MODEL_TRAINING_DAYS
  if (Mode == 'ENSEMBLE') extract_amount <- -ENSEMBLE_TRAINING_DAYS
   
  features <- Features %>% 
    merge(Dates, by = "Date", all = FALSE) %>%
    top_n(extract_amount, Date)

  labels <- labels %>%
    top_n(extract_amount, Date)

  result <- list(features,
                labels)
  names(result) <- c('Features',
                    'Labels')
  return(result)
}

train_or_load_models <- function(Dateranges, Features, Labels) {
  model_lists = list()
  if (ANALYSIS_MODE == 0 | ANALYSIS_MODE == 1) { # train models for each date
    for (i in 1 : length(Dateranges)) {
      daterange = Dateranges[[i]]
      model_lists[i] = extract_training_data(daterange, Features, Labels, Mode = 'MODEL') %>%
                        train_models() %>%
                        list()
    }
  }
  return(model_lists)
}

train_or_load_ensembles <- function(Dateranges, Features, Labels, Model_Lists) {
  ensembles = list()
  if (ANALYSIS_MODE == 0 | ANALYSIS_MODE == 1) { # train models for each date
    for (i in 1 : length(Dateranges)) {
      daterange = Dateranges[[i]]
      model_list = Model_Lists[[i]]
      ensembles[i] = extract_training_data(daterange, Features, Labels, Mode = 'ENSEMBLE') %>%
                        train_ensemble(model_list) %>%
                        list()
    }
  }
  return(ensembles)
}

train_models <- function(Dataset) {
  
  ma_crossover <- train_MA_crossover_model(Dataset$Features, Dataset$Labels)
  exponential_ma <- 'Exponential MA Model'
  
  model_list <- list(ma_crossover, exponential_ma)
  names(model_list) <- c('ma_crossover', 'exponential_ma')
  return(model_list)
}

train_ensemble <- function(Dataset, Models) {
  ensemble = 'Ensemble_1'
  return(ensemble)
}

# ============================================================
# ============================================================
# ============================================================
# ============================================================
train_MA_crossover_model <- function(Features, Labels) {
  names(Labels)[2] = "Label"
  
  #Preprocessing
  training = Features %>%
    generate_MA_crossover_data(SHORT_MAS, LONG_MAS) %>%
    merge(Labels, by = "Date", all = FALSE) %>%
    select(-Date)
  
  # variable importance tuning grid
  xgb_grid_1 <- expand.grid(nrounds = 1, eta = 0.3, max_depth = 5, 
                            gamma = 0, colsample_bytree=1, 
                            min_child_weight=1, subsample = 1)
  
  # variable importance xgboost
  xgb_tree <-  train(Label ~ ., data = training,
                    trControl = trainControl(method="none"),
                    metric="logLoss", tuneGrid = xgb_grid_1, method = "xgbTree")
  
  xgbTree_imp <- varImp(xgb_tree, scale = FALSE)
  ggplot_imp <- ggplot(xgbTree_imp, top = 10)
  var_list <- xgbTree_imp$importance %>%
              rownames_to_column(var = "Variable") %>%
              mutate(Variable = str_replace_all(Variable,"`", "")) %>%
              filter(Overall > 0.01) %>%
              top_n(10, Overall)
  
  curated_training <- training %>%
    select(one_of(c(var_list$Variable, 'Label')))
    
  model_properties = list(ggplot_imp, 
                          var_list$Variable, 
                          curated_training)
  names(model_properties) = c('Feature_Importance_Plot', 
                              'Chosen_Features_Vector',
                              'Curated_Training_Set')
  
  return(model_properties)
}

# --------------------------------------------------------
# MA Crossover Features ----------------------------------
generate_MA_crossover_data <- function(Data, Short_MAS, Long_MAS) {
  count = 1
  for (i in 1 : length(Short_MAS)) {
    short_MA = Short_MAS[i]
    for (j in 1 : length(Long_MAS)) {
      long_MA = Long_MAS[j]
      if (long_MA > short_MA) {
        df = single_MA_crossover(Data, short_MA, long_MA)
        if (count == 1) {
          master = df
        } 
        else {
          master = merge(master, df, by = "Date", all = FALSE)
        }
        count = count + 1
      }
    }
  }
  return(master)
}

single_MA_crossover <- function(Data, short_MA, long_MA) {
  df = Data %>%
      arrange(Date) %>%
      mutate_at(vars(-Date), ~ (roll_mean(., short_MA, align = "right", fill = NA)) -
                (roll_mean(., long_MA, align = "right", fill = NA)))  %>%
      filter(!is.na(.[[2]])) %>%
      mutate_at(vars(-Date), scale)
  prefix = paste('MA', toString(short_MA), '-', 'MA', toString(long_MA), sep = '')
  
  names(df)[-1] <- paste(colnames(df)[-1], prefix, sep = ".")
  
  return(df)
}

# --------------------------------------------------------
# Feature Engineering Functions---------------------------

diff_dataframe <- function(Data, Offset) {
  if (Offset<0) {
    Data <- Data %>%
    mutate_at(vars(-Date), ~ . - lag(., -Offset)) %>%
    drop_na()
    diffstr <- paste('DiffN', toString(-Offset), sep = '')
  }
  else if (Offset>0) {
    Data <- Data %>%
    mutate_at(vars(-Date), ~ . - lead(., Offset)) %>%
    drop_na()
    diffstr <- paste('DiffP', toString(Offset), sep = '')
  }
  
  colnames <- names(Data)
  for (j in 1 : length(colnames)) {
    colname <- colnames[j]
    if (colname != 'Date') {
      colnames[j] <- paste(colname, diffstr, sep = '_')
    }
  }
  names(Data) <- colnames
  return(Data)
}

# At the moment of trading some data won't be available and some will
offsets_columns <- function(Data, Columns, Lags = NULL, Leads = NULL) {
  res <- Data %>% select(one_of(c('Date', Columns)))
  
  if (!is.null(Leads)) { #leading somme target columns
    for (i in 1:length(Columns)) {
      col_name <- Columns[i]
      lead_int <- Leads[i]
      new_col_name <- col_name
      if (lead_int > 0) new_col_name <- paste(col_name, '.LEAD', toString(lead_int), sep = "" )
      res <- res %>%
        mutate_at(vars(col_name), ~ lead(., lead_int)) %>%
        rename(!!new_col_name := !!col_name)
    }
  }
  else {
    for (i in 1:length(Columns)) {
      col_name <- Columns[i]
      lag_int <- Lags[i]
      new_col_name <- col_name
      if (lag_int > 0) new_col_name <- paste(col_name, '.LAG', toString(lag_int), sep = "" )
      res <-  res %>%
        mutate_at(vars(col_name), ~ lag(., lag_int)) %>%
        rename(!!new_col_name := !!col_name)
    }
  }
  
  res %>%  drop_na() %>% return()
}

lag_dataframe <- function(Data, Lag) {
  Data <- Data %>%
    mutate_at(vars(-Date), ~ lag(., Lag)) %>%
    drop_na()
    diffstr <- paste('Lag', toString(Lag), sep = '')
  
  colnames <- names(Data)
  for (j in 1 : length(colnames)) {
    colname <- colnames[j]
    if (colname != 'Date') {
      colnames[j] <- paste(colname, diffstr, sep = '_')
    }
  }
  names(Data) <- colnames
  return(Data)
}

lagsteps_and_expand_dataframe <- function(Data, Window, LagSteps) {
  master <- Data
  for (i in 1:LagSteps) {
    lag <- i * Window
    df <- lag_dataframe(Data, lag)
    master <- merge(master, df, by = "Date", all = FALSE)
  }
  return(master)
}

window_dataframe <- function(Data, Window, Function) {
  if (Function == 'Mean') {
    Data <- Data %>%
      arrange(Date) %>%
      mutate_at(vars(-Date), ~ roll_mean(., Window, align = "right", fill = NA)) %>%
      filter(!is.na(.[[2]]))
    diffstr <- paste('Mean', toString(Window), sep = '')
  }
  else if (Function == 'SD') {
    Data <- Data %>%
      arrange(Date) %>%
      mutate_at(vars(-Date), ~ roll_mean(., Window, align = "right", fill = NA)) %>%
      filter(!is.na(.[[2]]))
    diffstr <- paste('SD', toString(Window), sep = '')
  }
  
  colnames <- names(Data)
  for (j in 1 : length(colnames)) {
    colname <- colnames[j]
    if (colname != 'Date') {
      colnames[j] <- paste(colname, diffstr, sep = '_')
    }
  }
  names(Data) <- colnames
  return(Data)
}

multi_window_and_lagsteps <- function(Data, Windows, LagSteps, Funcs) {
  master <- lagsteps_and_expand_dataframe(Data, 1, LagSteps)
  for (i in 1 : length(Windows)) {
   window <- Windows[i]
   for (j in 1 : length(Funcs)) {
     func <- Funcs[j]
     df <- window_dataframe(Data, window, func)
     df <- lagsteps_and_expand_dataframe(df, window, LagSteps)
     master <- merge(master, df, by = "Date", all = FALSE)
   }
  }
  return(master)
}

generate_targets <- function(Targets, Diff_Class, Direction) {
  if (Direction == 'U') {
    df <- Targets %>%
       mutate_at(vars(-Date), ~ if_else(. > Diff_Class, 1, 0))
  }
  else if (Direction == 'D') {
    df <- Targets %>%
       mutate_at(vars(-Date), ~ if_else(. < -Diff_Class, 1, 0))
  }
  diffstr <- paste(Direction, toString(Diff_Class), sep = '')
  colnames <- names(df)
  for (j in 1 : length(colnames)) {
    colname <- colnames[j]
    if (colname != 'Date') {
      colnames[j] <- paste(colname, diffstr, sep = '_')
    }
  }
  names(df) <- colnames
  return(df)
}

multi_generate_targets <- function(Targets, Diff_Classes) {
  master <- Targets
  for (i in 1 : length(Diff_Classes)) {
    diff_class <- Diff_Classes[i]
    udf <- generate_targets(Targets, diff_class, 'U')
    master <- merge(master, udf, by = "Date", all = FALSE)
    ddf <- generate_targets(Targets, diff_class, 'D')
    master <- merge(master, ddf, by = "Date", all = FALSE)
  }
  return(master)
}

standardise_all_columns <- function(Data) {
  Data %>%
    mutate_at(vars(-Date), ~scale(.)) %>%
    return()
}

dates_dataframe <- function(Data) {
  Data %>%
    mutate(Part_Of_Year = yday(Date)/365) %>%
    mutate(Part_Of_Month = day(Date)/31) %>%
    mutate(Part_Of_Week = case_when(weekdays(Date) == 'Monday' ~ 0,
                           weekdays(Date) == 'Tuesday' ~ 0.25,
                           weekdays(Date) == 'Wednesday' ~ 0.5,
                           weekdays(Date) == 'Thursday' ~ 0.75,
                           weekdays(Date) == 'Friday' ~ 1.0, TRUE ~ 0.0)) %>%
  return()
}

# --------------------------------------------------------
# Charting Functions--------------------------------------

make_histograms <- function(Data) {
  nrows <- as.integer(ncol(Data) / 5)
  Data %>%
    melt(id.vars='Date',variable.name='series') %>%
    ggplot() +
    aes(x = value, Fill='Red', opacity = 0.7) + 
    geom_density() +
    facet_wrap(. ~ series, nrow = 4)
}

```

#### Data Loading
```{r Data Loading and cleaning, results = 'hide'}
master_data <- master_dataframe(DATA_FILES, c(FEATURE_COLS, TARGET_COLS))

features <- master_data %>% 
            offsets_columns(Columns = FEATURE_COLS, Lags = FEATURE_LAGS)

labels <- master_data %>% 
          offsets_columns(Columns = TARGET_COLS, Leads = TARGET_LEADS)
  
dateranges <- create_dateranges(features, labels)

```

#### Model Loading
```{r train or load models, results = 'hide'}

model_lists <- train_or_load_models(dateranges, features, labels)

#model_lists <- train_or_load_models(Datasets = datasets)

#ensembles <- train_or_load_ensembles(Datasets = datasets, Model_Lists = model_lists)

```
