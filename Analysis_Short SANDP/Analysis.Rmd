---
title: "Short S & P Analysis"
author: "Michael Dowd"
date: "12/4/2019"
output: html_document
---

```{r setup, include=FALSE, results='hide'}
knitr::opts_chunk$set(echo = FALSE)
library('tidyverse')
library('lubridate')
library('reshape2')
library('corrplot')
library('RcppRoll')
library('ggjoy')
library('gridExtra')
library('caret')
library(mlbench)
library(nnet)
set.seed(42)
```

```{r Global Variables, include=FALSE, results='hide'}
# Analysis Mode
# 0 - Full Backtest: run over a over historic days with retraining after every day
# 1 - Retrain: retrain models using the latest data
# 2 - Prediction: just load data and run predictions using the latest data
# 3 - Partial Backtest: for debugging, skip the retraining 
ANALYSIS_MODE = 0
BACKTEST_DAYS = 5
MODEL_TRAINING_DAYS = 10
ENSEMBLE_TRAINING_DAYS = 10

# Targets and Features
DATA_FILES <- c('SANDP.csv', 'DJI.csv', 'VIX.csv')
TARGET_COLS <- c('SANDP.Close')
TARGET_LEADS <- c(0) 
TARGET_DIFFS <- c(-0.1, -0.7) # std diff
FEATURE_COLS <- c('SANDP.Open', 'SANDP.High', 'SANDP.Low', 'SANDP.Close', 'DJI.Close', 'VIX.Close')
FEATURE_LAGS <- c(0, 1, 1, 1, 1, 1) 

# Feature Engineering
AGGREGATE_WINDOWS <- c(5) #, 10, 20) # 3
AGGREGATE_FUNCTIONS <- c('Mean') #, 'SD') # 3 x 2 = 6
LAGSTEPS <- 5 # 6 x (5 + 1) = 36, variable multiplier
DIFF_CLASSES <- c(0.1) # , 1, 2) # labels for small move, medium move and large move

# Display Options
VARS_TO_SHOW <-  20
```

```{r Functions, include=FALSE, results='hide'}

# --------------------------------------------------------
# Reading Functions---------------------------------------

master_dataframe <- function(Files, Columns) {
  parent_path <- substr(getwd(), 1, regexpr("\\/[^\\/]*$", getwd()))
  path <- paste(parent_path, 'Data/', sep = "")
  dataframes = vector("list", length(Files))
  for (i in 1 : length(Files)) {
    file <- Files[i]
    prefix <- str_replace(file, 'csv', '')
    df <- read_csv(paste(path, file, sep = ""))
    df <- df %>%
      mutate(Date=as.numeric(format(strptime(Date,"%Y-%m-%d"),"%Y%m%d"))) %>%
      discard(~all(is.na(.x))) %>%
      select(which(colSums(.) != 0)) %>%
      mutate(Date= as.Date(as.character(Date), "%Y%m%d")) %>%
      select(one_of(c('Date', str_replace(Columns, prefix, ''))))
    
    names(df)[-1] <- paste(prefix, colnames(df)[-1], sep = "")

    if (i == 1) {
      master <- df
    }
    else {
      master <- merge(master, df, by="Date")
    }
  }  
  return(master)
}

create_dateranges <- function(Features, Labels) {
  dates <- Features %>%
    merge(Labels, by = "Date", all = FALSE) %>%
    select(Date)
  dataframes <- list()
  steps <- c(1)
  n <- length(dates$Date)
  if (ANALYSIS_MODE == 0 | ANALYSIS_MODE == 3) steps <- c(BACKTEST_DAYS:1)
  index <- 1
  print(steps)
  for (i in steps) {
    latest_date <- sort(dates$Date,partial=n-i)[n-i]
    dataframes[index] <- dates %>%
      filter(Date <= latest_date) %>%
      arrange(desc(Date)) %>%
      top_n(MODEL_TRAINING_DAYS + ENSEMBLE_TRAINING_DAYS)
    index <- index + 1
  }
  
  return(dataframes)
}

# --------------------------------------------------------
# Feature Engineering Functions---------------------------

diff_dataframe <- function(Data, Offset) {
  if (Offset<0) {
    Data <- Data %>%
    mutate_at(vars(-Date), ~ . - lag(., -Offset)) %>%
    drop_na()
    diffstr <- paste('DiffN', toString(-Offset), sep = '')
  }
  else if (Offset>0) {
    Data <- Data %>%
    mutate_at(vars(-Date), ~ . - lead(., Offset)) %>%
    drop_na()
    diffstr <- paste('DiffP', toString(Offset), sep = '')
  }
  
  colnames <- names(Data)
  for (j in 1 : length(colnames)) {
    colname <- colnames[j]
    if (colname != 'Date') {
      colnames[j] <- paste(colname, diffstr, sep = '_')
    }
  }
  names(Data) <- colnames
  return(Data)
}

# At the moment of trading some data won't be available and some will
runtime_offsets <- function(Data, Columns, Lags = NULL, Leads = NULL) {
  res <- Data %>% select(one_of(c('Date', Columns)))
  
  if (!is.null(Leads)) { #leading somme target columns
    for (i in 1:length(Columns)) {
      col_name <- Columns[i]
      lead_int <- Leads[i]
      new_col_name <- col_name
      if (lead_int > 0) new_col_name <- paste(col_name, '.LEAD', toString(lead_int), sep = "" )
      res <- res %>%
        mutate_at(vars(col_name), ~ lead(., lead_int)) %>%
        rename(!!new_col_name := !!col_name)
    }
  }
  else {
    for (i in 1:length(Columns)) {
      col_name <- Columns[i]
      lag_int <- Lags[i]
      new_col_name <- col_name
      if (lag_int > 0) new_col_name <- paste(col_name, '.LAG', toString(lag_int), sep = "" )
      res <-  res %>%
        mutate_at(vars(col_name), ~ lag(., lag_int)) %>%
        rename(!!new_col_name := !!col_name)
    }
  }
  
  res %>%  drop_na() %>% return()
}

lag_dataframe <- function(Data, Lag) {
  Data <- Data %>%
    mutate_at(vars(-Date), ~ lag(., Lag)) %>%
    drop_na()
    diffstr <- paste('Lag', toString(Lag), sep = '')
  
  colnames <- names(Data)
  for (j in 1 : length(colnames)) {
    colname <- colnames[j]
    if (colname != 'Date') {
      colnames[j] <- paste(colname, diffstr, sep = '_')
    }
  }
  names(Data) <- colnames
  return(Data)
}

lagsteps_and_expand_dataframe <- function(Data, Window, LagSteps) {
  master <- Data
  for (i in 1:LagSteps) {
    lag <- i * Window
    df <- lag_dataframe(Data, lag)
    master <- merge(master, df, by = "Date", all = FALSE)
  }
  return(master)
}

window_dataframe <- function(Data, Window, Function) {
  if (Function == 'Mean') {
    Data <- Data %>%
      arrange(Date) %>%
      mutate_at(vars(-Date), ~ roll_mean(., Window, align = "right", fill = NA)) %>%
      filter(!is.na(.[[2]]))
    diffstr <- paste('Mean', toString(Window), sep = '')
  }
  else if (Function == 'SD') {
    Data <- Data %>%
      arrange(Date) %>%
      mutate_at(vars(-Date), ~ roll_mean(., Window, align = "right", fill = NA)) %>%
      filter(!is.na(.[[2]]))
    diffstr <- paste('SD', toString(Window), sep = '')
  }
  
  colnames <- names(Data)
  for (j in 1 : length(colnames)) {
    colname <- colnames[j]
    if (colname != 'Date') {
      colnames[j] <- paste(colname, diffstr, sep = '_')
    }
  }
  names(Data) <- colnames
  return(Data)
}

multi_window_and_lagsteps <- function(Data, Windows, LagSteps, Funcs) {
  master <- lagsteps_and_expand_dataframe(Data, 1, LagSteps)
  for (i in 1 : length(Windows)) {
   window <- Windows[i]
   for (j in 1 : length(Funcs)) {
     func <- Funcs[j]
     df <- window_dataframe(Data, window, func)
     df <- lagsteps_and_expand_dataframe(df, window, LagSteps)
     master <- merge(master, df, by = "Date", all = FALSE)
   }
  }
  return(master)
}

generate_targets <- function(Targets, Diff_Class, Direction) {
  if (Direction == 'U') {
    df <- Targets %>%
       mutate_at(vars(-Date), ~ if_else(. > Diff_Class, 1, 0))
  }
  else if (Direction == 'D') {
    df <- Targets %>%
       mutate_at(vars(-Date), ~ if_else(. < -Diff_Class, 1, 0))
  }
  diffstr <- paste(Direction, toString(Diff_Class), sep = '')
  colnames <- names(df)
  for (j in 1 : length(colnames)) {
    colname <- colnames[j]
    if (colname != 'Date') {
      colnames[j] <- paste(colname, diffstr, sep = '_')
    }
  }
  names(df) <- colnames
  return(df)
}

multi_generate_targets <- function(Targets, Diff_Classes) {
  master <- Targets
  for (i in 1 : length(Diff_Classes)) {
    diff_class <- Diff_Classes[i]
    udf <- generate_targets(Targets, diff_class, 'U')
    master <- merge(master, udf, by = "Date", all = FALSE)
    ddf <- generate_targets(Targets, diff_class, 'D')
    master <- merge(master, ddf, by = "Date", all = FALSE)
  }
  return(master)
}

standardise_all_columns <- function(Data) {
  Data %>%
    mutate_at(vars(-Date), ~scale(.)) %>%
    return()
}

dates_dataframe <- function(Data) {
  Data %>%
    mutate(Part_Of_Year = yday(Date)/365) %>%
    mutate(Part_Of_Month = day(Date)/31) %>%
    mutate(Part_Of_Week = case_when(weekdays(Date) == 'Monday' ~ 0,
                           weekdays(Date) == 'Tuesday' ~ 0.25,
                           weekdays(Date) == 'Wednesday' ~ 0.5,
                           weekdays(Date) == 'Thursday' ~ 0.75,
                           weekdays(Date) == 'Friday' ~ 1.0, TRUE ~ 0.0)) %>%
  return()
}

# --------------------------------------------------------
# Charting Functions--------------------------------------

make_histograms <- function(Data) {
  nrows <- as.integer(ncol(Data) / 5)
  Data %>%
    melt(id.vars='Date',variable.name='series') %>%
    ggplot() +
    aes(x = value, Fill='Red', opacity = 0.7) + 
    geom_density() +
    facet_wrap(. ~ series, nrow = 4)
}

```

#### Feature and Label Expansion
```{r Data Loading and cleaning, results='hide'}
data <- master_dataframe(DATA_FILES, c(FEATURE_COLS1, TARGET_COLS))

features <- data %>%
  runtime_offsets(Columns = FEATURE_COLS, Lags = FEATURE_LAGS)

labels <- data %>%
  runtime_offsets(Columns = TARGET_COLS, Leads = TARGET_LEADS)
  
dateranges <- create_dateranges(features, labels)

#features <- data %>%
#  diff_dataframe(-1) %>%
#  standardise_all_columns() %>%
#  multi_window_and_lagsteps(AGGREGATE_WINDOWS, LAGSTEPS, AGGREGATE_FUNCTIONS) %>%
#  dates_dataframe()

#labels <- data %>% 
#  diff_dataframe(1) %>%
#  standardise_all_columns() %>% 
#  multi_generate_targets(DIFF_CLASSES)

```

|               | Number of Samples | Features per Sample | Labels per Sample |
| ------------- |:-------------:| -----:| -----:|
| Original Samples | `r nrow(data)` | `r ncol(data)` | `r ncol(data)` |
| Transformed Samples | `r nrow(features)` | `r ncol(features)` | `r ncol(labels)` |

#### Biggest Statistically significant Correlations
```{r Correlation matrix}
merged <- features %>%
  merge(labels, by = "Date") %>%
  select(-Date) %>%
  discard(~all(is.na(.x)))

corr_mat <- cor(merged)
p_mat <- cor.mtest(merged, conf.level = 0.99)

corr_df <- data.frame(corr = double(), 
                      pval = double(), 
                      i_ind = integer(), 
                      j_ind = integer(),
                      i_Name = character(),
                      j_Name = character())
for (i in 1 : (ncol(features) - 1)) {
  for (j in (ncol(features) : ncol(merged))) {
    corr <- corr_mat[i, j]
    pval <- p_mat$p[i, j]
    i_ind <- i
    j_ind <- j
    i_Name <- colnames(merged)[i]
    j_Name <- colnames(merged)[j]
    corr_df <- rbind(corr_df, data.frame(corr,
                                         pval, 
                                         i_ind, 
                                         j_ind, 
                                         i_Name,
                                         j_Name))
  }
}
```

```{r Correlation plot, fig.width=12, fig.height=10}
x <- corr_df %>%
  filter(pval<0.01) %>%
  group_by(i_ind) %>%
  summarise(corr = max(corr)) %>%
  arrange(desc(abs(corr))) %>%
  top_n(VARS_TO_SHOW) %>%
  distinct(i_ind) %>%
  pull(i_ind)
y <- corr_df %>%
  filter(pval<0.01) %>%
  group_by(j_ind) %>%
  summarise(corr = max(corr)) %>%
  arrange(desc(abs(corr))) %>%
  top_n(VARS_TO_SHOW) %>%
  distinct(j_ind) %>%
  pull(j_ind)

#Correlation plot of top
corrplot(corr_mat[x, y], tl.cex = 1)
```

#### Statistically significant (p-value < 0.01) Correlations for target variables
```{r Correlation distributions, fig.width=12}
# box plot for 
plot1 <- corr_df %>%
  filter(pval<0.01) %>%
  mutate(j_Name = reorder(j_Name, corr**2, sum)) %>%
  ggplot() +
  aes(x = corr**2, y = j_Name, fill = j_Name) +
  geom_joy() + 
  ylab('') + 
  xlab('Squared Correlation Distribution') +
  theme(legend.position = "none",
        axis.text.y = element_blank())

plot2 <- corr_df %>%
  filter(pval<0.01 )%>%
  group_by(j_Name) %>%
  summarise(sum_corr_squared = sum(corr**2)) %>%
  ggplot() +
  aes(x = reorder(j_Name, sum_corr_squared), y = sum_corr_squared, fill = sum_corr_squared) +
  geom_bar(stat="identity") +
  coord_flip() + 
  xlab('') +
  ylab('Sum of Squared Correlation') + 
  theme(axis.text.y = element_text(size = 12),
        legend.position = "none")

grid.arrange(plot2, plot1, ncol=2)
```

#### Training and Testing Data
```{r Training and Testing data}
inTraining <- createDataPartition(features[[2]], p = .75, list = FALSE)
training <- labels %>%
  select(Date, High_SANDP_DiffP1_U1) %>%
  mutate(label = if_else(High_SANDP_DiffP1_U1 == 1, 'GO', 'ST')) %>%
  merge(diff[inTraining, ], by = "Date", all = FALSE) %>%
  select(-Date, -High_SANDP_DiffP1_U1)

testing <- labels %>%
  select(Date, High_SANDP_DiffP1_U1) %>%
  mutate(label = if_else(High_SANDP_DiffP1_U1 == 1, 'GO', 'ST')) %>%
  merge(diff[-inTraining, ], by = "Date", all = FALSE) %>%
  select(-Date, -High_SANDP_DiffP1_U1)

## 3-fold CV with 10 repetitions
fitControl <- trainControl(
  method = "repeatedcv",
  number = 3,
  repeats = 3)

# baselines
n_zeros <- training %>% filter(label=='ST') %>% nrow()
n_ones <- training %>% filter(label=='GO') %>% nrow()
n_tot <- training %>% nrow()

just_stays <- training %>%
  filter(label == 'ST') %>%
  top_n(n_ones, .[[2]]) 

training_bal <- training %>%
  filter(label == 'GO') %>%
  rbind(just_stays)

print(paste('Training set size: ', toString(nrow(training))))
print(paste('All zeros baseline accuracy: ', toString(n_zeros/n_tot)))

print(paste('Balanced Training set size: ', toString(nrow(training_bal))))
print('All zeros baseline accuracy: 0.5')
```

|               | Number of Samples | All Zeros Baseline |
| ------------- |:-------------:| -----:|
| Training Set | `r nrow(training)` | `r n_zeros/n_tot` |
| Balanced Training Set | `r nrow(training_bal)` | 0.5 |

``` {r pearson's correlation Variable search, fig.height = 6, fig.width=12}
cor <- training %>%
  select(label) %>%
  mutate(label = if_else(label == "GO", 1, 0)) %>%
  as.matrix() %>%
  cor(as.matrix(select(training, -label)))

cor_bal <- training_bal %>%
  select(label) %>%
  mutate(label = if_else(label == "GO", 1, 0)) %>%
  as.matrix() %>%
  cor(as.matrix(select(training_bal, -label)))
```

``` {r xgradientboost tree variable search, fig.height = 6, fig.width=12}
xgbTree <- train(label ~ ., data = training, 
                 method = "xgbTree")
gbmImp <- varImp(xgbTree, scale = FALSE)

xgbTree_bal <- train(label ~ ., data = training_bal, 
                 method = "xgbTree")
gbmImp_bal <- varImp(xgbTree_bal, scale = FALSE)
```

``` {r variable search graphs, fig.width=12}
plot1 <- data.frame(data = colnames(cor), abs_corr = abs(cor[1,])) %>%
  top_n(20, abs_corr) %>%
  ggplot() +
  aes(x = reorder(data, abs_corr), y = abs_corr) +
  geom_bar(stat="identity") +
  xlab('')+
  coord_flip()

plot2 <- data.frame(data = colnames(cor_bal), abs_corr = abs(cor_bal[1,])) %>%
  top_n(20, abs_corr) %>%
  ggplot() +
  aes(x = reorder(data, abs_corr), y = abs_corr) +
  geom_bar(stat="identity") +
  xlab('')+
  coord_flip()

plot3 <- ggplot(gbmImp, top = 20) + xlab('')
plot4 <- ggplot(gbmImp_bal, top = 20) + xlab('')
grid.arrange(plot1, plot2, plot3, plot4, nrow=2,ncol=2)
```

``` {r Linear Model}
gbmGrid1 <- expand.grid(interaction.depth = c(1,5,9), n.trees = (1:30)*50, shrinkage = 0.1, n.minobsinnode=20)

gbmFit1 <- train(label ~ ., data = training, method = "gbm", trControl = fitControl,
                 verbose = FALSE, tuneGrid = gbmGrid1, metric = "Kappa")
gbmFit1_bal <- train(label ~ ., data = training_bal, method = "gbm", trControl = fitControl, 
                     verbose = FALSE, tuneGrid = gbmGrid1)
```

``` {r K Nearest Neighbours}
gbmGrid2 <- expand.grid(k= (3:20))
gbmFit2 <- train(label ~ ., data = training, method = "knn", metric = "Kappa",
                 trControl = fitControl, tuneGrid = gbmGrid2)
gbmFit2_bal <- train(label ~ ., data = training_bal, method = "knn", 
                     trControl = fitControl, tuneGrid = gbmGrid2)
```

```{r neural network model}
gbmGrid3 <- expand.grid(size= (5:10), decay = c(1.0e-3, 1.0e-2, 1.0e-1))
gbmFit3 <- train(label ~ ., data = training, method = "nnet", metric = "Kappa",
                 trControl = fitControl, tuneGrid = gbmGrid3)
gbmFit3_bal <- train(label ~ ., data = training_bal, method = "nnet",
                 trControl = fitControl, tuneGrid = gbmGrid3)
```

#### Cross validated model params and accuracies
``` {r model plots, fig.width = 12, fig.height = 12}

plot1 <- plot(gbmFit1, metrick = "Kappa")
plot2 <- plot(gbmFit1_bal, metrick = "Kappa")

plot3 <- plot(gbmFit2, metric = "Kappa")
plot4 <- plot(gbmFit2_bal, metric = "Kappa")

plot5 <- plot(gbmFit3, metric="Kappa")
plot6 <- plot(gbmFit3_bal, metric="Kappa")

grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, nrow = 3, ncol = 2)
```